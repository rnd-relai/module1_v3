{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vinlist.csv not available\n",
      "vin_list intialized with test list !!\n",
      "bucket, W, x, y, vin_list, path, path2, path3, list_col, odo,ic\n",
      "list_col\n"
     ]
    }
   ],
   "source": [
    "# Define IAM role\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "import Input_Config # Input Config - To be initialised\n",
    "Input_Config.help()\n",
    "bucket, W, x, y, vin_list, path, path2, path3, list_col, odo, ic = Input_Config._init_()\n",
    "\n",
    "import Dummy_Config\n",
    "Dummy_Config.help()\n",
    "list_col = Dummy_Config._init_()\n",
    "\n",
    "global bucket, W, x, y, vin_list, path, path2, path3, list_col, odo, ic\n",
    "\n",
    "from d1 import path1cc, Tsim1, Tsim1pow\n",
    "from statedwell import statedwell\n",
    "from alertstat import alertstat\n",
    "from d2 import s3_write\n",
    "import Annotations\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket=\"relai.poc.temp\"\n",
    "folder_base='saurabh/'\n",
    "file_extn='.csv'\n",
    "\n",
    "from d2 import get_vin_list\n",
    "f1=get_vin_list(bucket=bucket, folder_base=folder_base, file_extn=file_extn)  #reading source\n",
    "#f2=get_vin_list(bucket=bucket, folder_base='res/1/', file_extn=file_extn)  #reading already done\n",
    "#f3= list( set(f1)-set(f2) ) # picking the remaining to do\n",
    "f4=get_vin_list(bucket=bucket, folder_base='jcd/', file_extn=file_extn)  #reading source\n",
    "f5=list(pd.read_excel('s3://{}/{}{}'.format(bucket,'0tmp/','vin_239.xlsx'))['vin'])\n",
    "f6=f4+f5[0:40]\n",
    "#path = 's3://{}/{}/{}.csv'.format(bucket,folder_base,vin)\n",
    "#'s3://{}/{}{}.csv'.format(bucket,'alert/',vin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MB1CTCFD6HAEG4844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/module1/statedwell.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df3a['time']=pd.to_datetime(df3a['EVENT_UTC1'])\n"
     ]
    }
   ],
   "source": [
    "xy_data_list = []\n",
    "file_counter=0\n",
    "for vin in f6[69:]:  # .. # 4527-done .. 46 skipped .. FILES data corrupt!\n",
    "    file_counter+=1\n",
    "    print(file_counter, vin)\n",
    "    file_periodic = 's3://{}/{}{}.csv'.format(bucket,folder_base,vin)\n",
    "    file_alert    = 's3://{}/{}{}.csv'.format(bucket,'alert/',vin)\n",
    "    cf1_p=0\n",
    "    try:\n",
    "        df1_p = pd.read_csv(file_periodic)\n",
    "        df1_p['ENGINE_SPEED_x'] = df1_p['ENGINE_SPEED_y']\n",
    "        df1_p['ENGINE_SPEED'] = df1_p['ENGINE_SPEED_y']\n",
    "        cf1_p=1\n",
    "    except:\n",
    "        print(vin+\" ---- Not Available\")\n",
    "        cf1_p=0\n",
    "        \n",
    "    if (cf1_p==1): \n",
    "        df3r=statedwell(W, df1_p)\n",
    "        df1 = df1_p[df1_p['ENGINE_SPEED_x']>0]\n",
    "        \n",
    "    cf1_c=0\n",
    "    try:\n",
    "        df1_c = pd.read_csv(file_alert)\n",
    "        cf1_c=1\n",
    "    except:\n",
    "        print(file_alert+'.csv'+\"  Not Available\")\n",
    "        cf1_c=0\n",
    "    \n",
    "    if (cf1_c==1): df_temp0=alertstat(W, df1_p, df1_c)\n",
    "    else : df_temp0=pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    from d2 import power\n",
    "    df1 = power(df1)\n",
    "    list_col = list(set(df1.columns) - set(['Unnamed: 0', 'GPS_SPEED_x',\n",
    "                                             'ACT_WHL_SPEED','EVENT_UTC1', 'LATITUDE_x', 'LONGITUDE_x', 'ALTITUDE_x', 'HEADING_x',    \n",
    "                                             'NO_OF_SAT_x', 'ENGINE_SPEED_y', 'WHEEL_SPEED_y', 'GPS_SPEED_y','IGNITION_STATUS_x', 'VEHICLE_ODO_x','GPS_ODO_x', 'ws1', 'odo', 'gear',\n",
    "                                             'CLUTCH_PEDAL', 'BRAKE_PEDAL', 'ENGINE_HRS', 'DIST_TO_EMPTY', 's_ang','c_ang', 'alpha', 'trp', 'mass']\n",
    "                                           )\n",
    "                    )\n",
    "    \n",
    "    \n",
    "    ldf=[]\n",
    "    for i in list_col:\n",
    "        if(i in ['power[-inf,0]','power[0,25]','power[25,75]','power[75,inf]']):\n",
    "            df10 = Tsim1pow(P1=df1[i],odo=df1['odo'], P_name=i)\n",
    "            ldf.append(df10)#.to_csv(i+\".csv\")\n",
    "        else:\n",
    "            df10 = Tsim1(P1=df1[i],odo=df1['odo'], P_name=i)\n",
    "            ldf.append(df10)#.to_csv(i+\".csv\")\n",
    "    \n",
    "            \n",
    "    if (df3r.shape[0]>0):\n",
    "        if (df_temp0.shape[0]>0):\n",
    "            df3r=pd.concat([df3r,df_temp0], axis=1)#, sort=False\n",
    "        \n",
    "    df_temp1=pd.concat(ldf, axis=1)#, sort=False\n",
    "    df_temp2=pd.concat([df3r,df_temp1], axis=1)#, sort=False\n",
    "    \n",
    "    #----- Annotations ----- # skip-POC- Nirumal & Aseena taking care of populating display\n",
    "    '''  \n",
    "    col_L2_sys = Input_Config.col_L2_sys # name of column in jcd having L2-sys components\n",
    "    if (df_temp2.shape[0]>0): \n",
    "        df_temp2=Annotations.Annotations_egr(df_temp2, col_L2_sys, path+'/1', vin) \n",
    "        xy_data_list.append(df_temp2)\n",
    "        _=s3_write(bucket, 'res/1/{}.csv'.format(vin), df_temp2)\n",
    "    '''\n",
    "    _=s3_write(bucket, 'res/1/{}.csv'.format(vin), df_temp2)\n",
    "    \n",
    "    df_temp2['vin']=vin\n",
    "    xy_data_list.append(df_temp2)\n",
    "    # ---- end of vin-wise ----\n",
    "    \n",
    "df_temp3=pd.concat(xy_data_list, axis=0)\n",
    "_=s3_write(bucket, 'res/2/batch_{}.csv'.format('POC_EGR_batch'), df_temp3)\n",
    "#-------------------------\n",
    "\n",
    "#from fsa import anova, pca, tsne\n",
    "\n",
    "# Anova - F>1 : of df_temp3: box plots\n",
    "# PCA of (# F>1) : scatterplots\n",
    "# tsne - of concat(x_data_list) : scatterplots\n",
    "# tsne - of (# F>1) : scatterplots\n",
    "#--------------------------------\n",
    "\n",
    "# import prediction_model as pm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
